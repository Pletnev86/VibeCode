# âš¡ Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ ÑÑ‚Ð°Ñ€Ñ‚: ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ OpenRouter

## ðŸŽ¯ ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ

1. **Ð‘ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ð°Ñ:** `deepseek/deepseek-r1:free`
2. **ÐŸÐ»Ð°Ñ‚Ð½Ð°Ñ #1:** `deepseek/deepseek-r1`
3. **ÐŸÐ»Ð°Ñ‚Ð½Ð°Ñ #2:** `anthropic/claude-3.5-sonnet`
4. **ÐŸÐ»Ð°Ñ‚Ð½Ð°Ñ #3:** `openai/gpt-4o-mini`
5. **Fallback:** Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ (LM Studio)

---

## ðŸ“ ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð´ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ°

### 1. ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ (Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð² Ð½Ð°Ñ‡Ð°Ð»Ð¾ Ñ„Ð°Ð¹Ð»Ð°)

```javascript
const FREE_MODEL = 'deepseek/deepseek-r1:free';
const PAID_MODELS = [
  process.env.OPENROUTER_PAID_MODEL_1 || 'deepseek/deepseek-r1',
  process.env.OPENROUTER_PAID_MODEL_2 || 'anthropic/claude-3.5-sonnet',
  process.env.OPENROUTER_PAID_MODEL_3 || 'openai/gpt-4o-mini',
];
const OPENROUTE_KEY = process.env.OPENROUTE_KEY || '';
```

### 2. Ð£Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸ÐµÐ¼

```javascript
const botModes = new Map();

function getBotMode(botId) {
    if (!botModes.has(botId)) {
        botModes.set(botId, { 
            currentModel: FREE_MODEL,
            paidModelIndex: 0
        });
    }
    return botModes.get(botId);
}

function setBotMode(botId, modeObj) {
    botModes.set(botId, { ...getBotMode(botId), ...modeObj });
}
```

### 3. Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° (ÐºÐ»ÑŽÑ‡ÐµÐ²Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ)

```javascript
async function queryLlm(messages, botId = 'default', recursionLevel = 0) {
  const botState = getBotMode(botId);
  const modelToUse = botState.currentModel || FREE_MODEL;

  try {
    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENROUTE_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model: modelToUse,
        messages: Array.isArray(messages) ? messages : [{ role: 'user', content: messages }],
        max_tokens: 512
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      const isQuotaError = response.status === 429 || response.status === 402;
      
      // ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð½Ð° Ð¿Ð»Ð°Ñ‚Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ ÐºÐ²Ð¾Ñ‚Ñ‹
      if (isQuotaError && botState.currentModel === FREE_MODEL && PAID_MODELS.length > 0) {
        const nextPaidModel = PAID_MODELS[botState.paidModelIndex || 0];
        setBotMode(botId, { 
          currentModel: nextPaidModel,
          paidModelIndex: botState.paidModelIndex || 0
        });
        if (recursionLevel < 1) {
          return await queryLlm(messages, botId, recursionLevel + 1);
        }
      }
      
      throw new Error(`API error: ${response.status}`);
    }

    const data = await response.json();
    const reply = data?.choices?.[0]?.message?.content?.trim() || '';
    
    // Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑƒÑÐ¿ÐµÑˆÐ½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    if (modelToUse !== FREE_MODEL) {
      setBotMode(botId, { currentModel: modelToUse });
    }
    
    return reply;
    
  } catch (err) {
    // ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð½Ð° ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÑƒÑŽ Ð¿Ð»Ð°Ñ‚Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    if (botState.paidModelIndex < PAID_MODELS.length - 1 && recursionLevel < PAID_MODELS.length) {
      const nextIndex = (botState.paidModelIndex || 0) + 1;
      setBotMode(botId, { 
        currentModel: PAID_MODELS[nextIndex],
        paidModelIndex: nextIndex
      });
      return await queryLlm(messages, botId, recursionLevel + 1);
    }
    
    throw err;
  }
}
```

---

## ðŸ”§ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· .env

```env
OPENROUTE_KEY=sk-or-v1-Ð²Ð°Ñˆ-ÐºÐ»ÑŽÑ‡
OPENROUTER_PAID_MODEL_1=deepseek/deepseek-r1
OPENROUTER_PAID_MODEL_2=anthropic/claude-3.5-sonnet
OPENROUTER_PAID_MODEL_3=openai/gpt-4o-mini
```

---

## âœ… Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ

```javascript
const response = await queryLlm('ÐŸÑ€Ð¸Ð²ÐµÑ‚!', 'user123');
```

---

**ÐŸÐ¾Ð»Ð½Ð°Ñ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ:** ÑÐ¼. `INSTRUKCIYA_PERENOS_MODEL_SWITCHING.md`

